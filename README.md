Q1- Why did you choose the particular algorithm?
ans - I have chosen the XGBoost algorithm because it offers high performance even with a large number of features and samples.
XGBoost is a highly flexible algorithm that can handle various data types and feature representations. Whether your dataset consists of numerical, categorical, or textual features, XGBoost can accommodate them with ease.
XGBoost also have tunning capabilities.

Q2 What are the different tuning methods used for the algorithm?
Ans - I have used grid search with cross-validation to tune the hyperparameters of the XGBoost classifier and to improve the  model performance and  to reduce the risk of overfitting. 

Q3 - Did you consider any other choice of algorithm ? why or why not?
Ans - Yes , i have consider other choice of algorithm which are Random Forest Classification and Multinomial Naive Bayes . Because Random Forest is  known for its simplicity, scalability, and robustness to overfitting.Random Forest is  effective in handling high-dimensional data . Multinomial Naive Bayes is known for its simplicity and efficiency, and is good option when dealing with text or categorical data.
But i have chosen XGBoost because i wanted to use different approach from other candidates , as we have not studies XGBoost in our curriculum so there are chances that other candidate might not be using this approach.

Q4 - What is the accuracy ?
Ans - 0.9116570831155254 this is the accuracy of my model.

Q5 - What are the different types of metrics that can be used to evaluate the model?
Ans -Accuracy , recall, precision , F1 Score.
